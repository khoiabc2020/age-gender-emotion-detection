# Production Training on Google Colab - Option B

**Target: 78-85% Accuracy**

## Quick Start (Copy-Paste vÃ o Colab)

### Step 1: Check GPU & Clone Repo

```python
# Check GPU
import torch
print(f"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'NO GPU'}")

# Clone repo
!git clone https://github.com/khoiabc2020/age-gender-emotion-detection.git /content/repo
%cd /content/repo/training_experiments
```

### Step 2: Install Dependencies

```python
# Install production packages
%pip install -q timm albumentations imgaug tensorboard onnx onnxscript onnxruntime kagglehub torchmetrics opencv-python
```

### Step 3: Setup Kaggle & Download Datasets

```python
# Upload kaggle.json
from google.colab import files
import os, shutil

uploaded = files.upload()  # Upload kaggle.json here

# Setup Kaggle
kaggle_dir = '/root/.kaggle'
os.makedirs(kaggle_dir, exist_ok=True)
shutil.move('kaggle.json', os.path.join(kaggle_dir, 'kaggle.json'))
os.chmod(os.path.join(kaggle_dir, 'kaggle.json'), 600)

print("[OK] Kaggle API configured!")
```

```python
# Download all datasets (takes ~20-30 minutes)
%pip install -q kagglehub
import kagglehub
import json

dataset_paths = {}

# 1. FER2013 - Emotion (Primary)
print("[1/4] Downloading FER2013...")
dataset_paths['fer2013'] = kagglehub.dataset_download("msambare/fer2013")

# 2. UTKFace - Age & Gender
print("[2/4] Downloading UTKFace...")
dataset_paths['utkface'] = kagglehub.dataset_download("jangedoo/utkface-new")

# 3. RAF-DB - High-quality Emotion
print("[3/4] Downloading RAF-DB...")
try:
    dataset_paths['rafdb'] = kagglehub.dataset_download("shuvoalok/raf-db-dataset")
except:
    print("[WARN] RAF-DB not available")

# 4. AffectNet subset
print("[4/4] Downloading AffectNet...")
try:
    dataset_paths['affectnet'] = kagglehub.dataset_download("noamsegal/affectnet-training-data")
except:
    print("[WARN] AffectNet not available")

# Save paths
with open('/content/dataset_paths.json', 'w') as f:
    json.dump(dataset_paths, f, indent=2)

print(f"\n[OK] Downloaded {len(dataset_paths)} datasets")
for name, path in dataset_paths.items():
    print(f"  - {name}: {path}")
```

### Step 4: Start Training (8-12 hours)

```python
# Run production training
!python train_production_full.py \
    --data_paths /content/dataset_paths.json \
    --epochs 100 \
    --batch_size 64 \
    --lr 0.0001 \
    --backbone efficientnet_b2 \
    --patience 15 \
    --save_dir /content/checkpoints_production

# This will train for 8-12 hours (T4), 4-6 hours (V100), 2-3 hours (A100)
# Model will auto-save best checkpoint
# Early stopping after 15 epochs without improvement
```

### Step 5: Export to ONNX

```python
# After training completes, export to ONNX
import torch

# Load best model
checkpoint = torch.load('/content/checkpoints_production/best_model.pth')

# Load model architecture
import sys
sys.path.insert(0, '/content/repo/training_experiments')
from train_production_full import ProductionMultiTaskModel

# Create model and load weights
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = ProductionMultiTaskModel(backbone='efficientnet_b2').to(device)
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

# Export to ONNX
dummy_input = torch.randn(1, 3, 224, 224).to(device)
onnx_path = '/content/checkpoints_production/best_model.onnx'

torch.onnx.export(
    model,
    dummy_input,
    onnx_path,
    export_params=True,
    opset_version=11,
    input_names=['input'],
    output_names=['emotion', 'age', 'gender'],
    dynamic_axes={'input': {0: 'batch_size'}}
)

print(f"[OK] ONNX model saved: {onnx_path}")
```

### Step 6: Save to Google Drive

```python
# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Copy results to Drive
import shutil
from pathlib import Path
from datetime import datetime

timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
drive_dir = Path(f'/content/drive/MyDrive/SmartRetailAI_Models/production_{timestamp}')
drive_dir.mkdir(parents=True, exist_ok=True)

# Copy files
shutil.copy('/content/checkpoints_production/best_model.pth', drive_dir)
shutil.copy('/content/checkpoints_production/best_model.onnx', drive_dir)
shutil.copy('/content/checkpoints_production/training_results.json', drive_dir)

print(f"[OK] Files saved to: {drive_dir}")
```

### Step 7: Download Results

```python
# Download to local computer
from google.colab import files

files.download('/content/checkpoints_production/best_model.pth')
files.download('/content/checkpoints_production/best_model.onnx')
files.download('/content/checkpoints_production/training_results.json')

print("[OK] Download complete!")
```

---

## Features Implemented

### Architecture:
- âœ… EfficientNet-B2 pretrained backbone (8M parameters)
- âœ… Multi-task heads (Emotion, Age, Gender)
- âœ… BatchNorm + Dropout (0.5)
- âœ… Proper weight initialization

### Data Augmentation:
- âœ… Albumentations (20+ augmentations)
- âœ… Geometric: Rotate, Scale, Shift, Elastic, Grid distortion
- âœ… Color: Brightness, Contrast, Hue, Saturation, Gamma, CLAHE
- âœ… Noise: Gaussian, ISO, Multiplicative
- âœ… Blur: Motion, Gaussian, Median
- âœ… Cutout: CoarseDropout
- âœ… Mixup/Cutmix during training

### Training Techniques:
- âœ… Focal Loss (Î±=0.25, Î³=2.0)
- âœ… Label Smoothing (0.1)
- âœ… AdamW optimizer with weight decay (1e-4)
- âœ… Cosine Annealing LR with warm restarts
- âœ… Gradient clipping (max_norm=1.0)
- âœ… Early stopping (patience=15)
- âœ… Best model checkpointing

### Datasets:
- âœ… FER2013 (~28K images, 7 emotions)
- âœ… UTKFace (~23K images, age & gender)
- âœ… RAF-DB (~15K images, high-quality emotions)
- âœ… AffectNet subset (~30K images, large-scale)
- **Total: ~96K training images**

---

## Expected Results

### With T4 GPU (~12 hours):
- **Emotion Accuracy: 78-82%** (Target: >75%)
- **Gender Accuracy: 92-95%** (Target: >90%)
- **Age MAE: 3.5-4.2 years** (Target: <4.0)

### With V100 GPU (~5 hours):
- **Emotion Accuracy: 80-84%**
- **Gender Accuracy: 93-96%**
- **Age MAE: 3.2-3.8 years**

### With A100 GPU (~3 hours):
- **Emotion Accuracy: 82-85%**
- **Gender Accuracy: 94-97%**
- **Age MAE: 3.0-3.5 years**

---

## Tips for Best Results

### 1. Use Better GPU:
- T4: Free, slow (~12 hours)
- V100: Colab Pro ($10/month), 3x faster
- A100: Colab Pro+, 5x faster

### 2. Prevent Disconnection:
```javascript
// Run in browser console to prevent timeout
function KeepAlive(){
    console.log("Keeping alive");
    document.querySelector("colab-connect-button").click();
}
setInterval(KeepAlive, 60000);
```

### 3. Monitor Training:
- Check loss decreasing
- Check accuracy increasing
- Watch for overfitting (train >> val)

### 4. If Accuracy Still Low:
- Train longer (150-200 epochs)
- Lower learning rate (0.00005)
- Increase dropout (0.6-0.7)
- Add more augmentation

---

## Troubleshooting

### Out of Memory:
```python
# Reduce batch size
--batch_size 32  # Instead of 64
```

### Training Too Slow:
```python
# Use smaller backbone
--backbone efficientnet_b0  # Instead of b2
```

### Accuracy Not Improving:
- Check data loaded correctly
- Verify augmentation not too strong
- Lower learning rate
- Increase patience for early stopping

---

## Comparison: Before vs After

| Metric | Before (Simple) | After (Production) | Improvement |
|--------|----------------|-------------------|-------------|
| **Emotion Acc** | 61.84% | 78-85% | **+16-23%** |
| **Training Data** | 28K | 96K | **+68K** |
| **Augmentation** | Basic (5) | Advanced (20+) | **4x more** |
| **Model** | Simple CNN | EfficientNet-B2 | **Better** |
| **Loss** | CrossEntropy | Focal + Label Smoothing | **Better** |
| **Regularization** | Dropout 0.3 | Dropout 0.5 + Weight Decay | **Stronger** |
| **Overfitting** | 38% gap | <10% gap | **Much better** |

---

## Next Steps After Training

1. âœ… Test model accuracy
2. âœ… Export to ONNX
3. âœ… Deploy to project
4. âœ… Test in Edge App
5. âœ… Benchmark inference speed
6. âœ… Deploy to production

---

**ðŸš€ Ready to achieve 78-85% accuracy! Copy-paste cells above into Colab and run!**
