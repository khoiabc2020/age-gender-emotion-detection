{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_qM97cIJIza"
      },
      "source": [
        "# üöÄ Smart Retail AI - Training on Google Colab\n",
        "\n",
        "**Train model v·ªõi GPU mi·ªÖn ph√≠ - 9 b∆∞·ªõc ƒë∆°n gi·∫£n!**\n",
        "\n",
        "## üìã Checklist tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu:\n",
        "- ‚úÖ Runtime ‚Üí Change runtime type ‚Üí **GPU (T4)**\n",
        "- ‚úÖ C√≥ file **kaggle.json** (l·∫•y t·∫°i: https://www.kaggle.com/settings/account)\n",
        "\n",
        "## ‚è±Ô∏è Th·ªùi gian ∆∞·ªõc t√≠nh:\n",
        "- Setup: 5 ph√∫t\n",
        "- Download datasets: 10-15 ph√∫t  \n",
        "- Training: 45-60 ph√∫t\n",
        "- **Total: ~1 gi·ªù 20 ph√∫t**\n",
        "\n",
        "## üìä K·∫øt qu·∫£ mong ƒë·ª£i:\n",
        "- Gender Accuracy: > 90%\n",
        "- Emotion Accuracy: > 75%\n",
        "- Age MAE: < 4.0 years\n",
        "\n",
        "---\n",
        "\n",
        "**üöÄ Ch·∫°y t·ª´ng cell theo th·ª© t·ª± t·ª´ tr√™n xu·ªëng!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJhsHuXrJIzb",
        "outputId": "18516f4f-cb9c-4915-80d8-35a0f41fa79f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ ƒê√£ c√†i ƒë·∫∑t xong c√°c th∆∞ vi·ªán!\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# CELL 1: CHECK GPU\n",
        "# ============================================================\n",
        "import torch\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"GPU CHECK\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    print(\"\\n[OK] GPU T4 is ready!\")\n",
        "else:\n",
        "    print(\"\\n[ERROR] NO GPU! Please enable:\")\n",
        "    print(\"   Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU\")\n",
        "    \n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "ow0CdGRaJIzd",
        "outputId": "a44a540e-1dfa-4897-e992-d4013a5f7dc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.9.0+cu126\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "module 'torch.cuda' has no attribute 'is_is_available'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1003209842.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"PyTorch version: {torch.__version__}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"CUDA available: {cuda.is_is_available()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"CUDA version: {torch.version.cuda}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Corrected line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torch.cuda' has no attribute 'is_is_available'"
          ]
        }
      ],
      "source": [
        "# This cell is removed - use Cell 1 instead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1hHs5K2JIze"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 2: CLONE REPOSITORY\n",
        "# ============================================================\n",
        "import os\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"CLONE REPOSITORY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "repo_dir = '/content/repo'\n",
        "\n",
        "if not os.path.exists(repo_dir):\n",
        "    print(\"\\n[INFO] Cloning from GitHub...\")\n",
        "    !git clone https://github.com/khoiabc2020/age-gender-emotion-detection.git {repo_dir}\n",
        "    print(\"[OK] Repository cloned!\")\n",
        "else:\n",
        "    print(\"\\n[INFO] Repository exists, pulling latest...\")\n",
        "    !cd {repo_dir} && git pull\n",
        "    print(\"[OK] Repository updated!\")\n",
        "\n",
        "# Navigate to training directory\n",
        "%cd {repo_dir}/training_experiments\n",
        "\n",
        "print(f\"\\n[INFO] Current directory:\")\n",
        "!pwd\n",
        "\n",
        "print(\"\\n[INFO] Directory structure:\")\n",
        "!ls -la\n",
        "\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRqXpy3aJIze"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 3: SETUP KAGGLE API\n",
        "# ============================================================\n",
        "from google.colab import files\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"SETUP KAGGLE API\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\n[INFO] Please upload your kaggle.json file\")\n",
        "print(\"   Get it from: https://www.kaggle.com/settings/account\")\n",
        "print(\"   ‚Üí Scroll to 'API' section\")\n",
        "print(\"   ‚Üí Click 'Create New API Token'\")\n",
        "print(\"   ‚Üí Download kaggle.json\\n\")\n",
        "\n",
        "# Upload kaggle.json\n",
        "uploaded = files.upload()\n",
        "\n",
        "if 'kaggle.json' in uploaded:\n",
        "    # Setup Kaggle directory\n",
        "    kaggle_dir = '/root/.kaggle'\n",
        "    os.makedirs(kaggle_dir, exist_ok=True)\n",
        "    \n",
        "    # Move and set permissions\n",
        "    kaggle_json = os.path.join(kaggle_dir, 'kaggle.json')\n",
        "    shutil.move('kaggle.json', kaggle_json)\n",
        "    os.chmod(kaggle_json, 600)\n",
        "    \n",
        "    print(\"\\n[OK] Kaggle API configured successfully!\")\n",
        "    print(\"=\" * 60)\n",
        "else:\n",
        "    print(\"\\n[ERROR] kaggle.json not found!\")\n",
        "    print(\"   Please upload kaggle.json to continue\")\n",
        "    print(\"=\" * 60)\n",
        "    raise Exception(\"Kaggle API key required\")\n",
        "\n",
        "# ============================================================\n",
        "# OPTION 2: Download t·ª´ Google Drive (file zip)\n",
        "# ============================================================\n",
        "if not USE_GITHUB:\n",
        "    # ƒê∆∞·ªùng d·∫´n file zip tr√™n Drive\n",
        "    import glob\n",
        "    zip_files = glob.glob('/content/drive/MyDrive/Colab_Training/training_experiments_*.zip')\n",
        "\n",
        "    if zip_files:\n",
        "        # L·∫•y file m·ªõi nh·∫•t\n",
        "        latest_zip = max(zip_files, key=os.path.getctime)\n",
        "        print(f\"üì¶ T√¨m th·∫•y file: {os.path.basename(latest_zip)}\")\n",
        "\n",
        "        # Gi·∫£i n√©n\n",
        "        print(\"üìÇ ƒêang gi·∫£i n√©n...\")\n",
        "        with zipfile.ZipFile(latest_zip, 'r') as zip_ref:\n",
        "            zip_ref.extractall('/content/project')\n",
        "        print(\"‚úÖ ƒê√£ gi·∫£i n√©n code\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y file zip tr√™n Drive\")\n",
        "        print(\"   H√£y upload file zip v√†o: /content/drive/MyDrive/Colab_Training/\")\n",
        "\n",
        "# Ki·ªÉm tra c·∫•u tr√∫c\n",
        "project_dir = Path('/content/project/training_experiments')\n",
        "if project_dir.exists():\n",
        "    print(f\"\\n‚úÖ Code ƒë√£ s·∫µn s√†ng t·∫°i: {project_dir}\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  C·∫ßn ki·ªÉm tra l·∫°i c·∫•u tr√∫c th∆∞ m·ª•c\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 4: DOWNLOAD DATASETS FROM KAGGLE\n",
        "# ============================================================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"DOWNLOADING DATASETS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Install kagglehub if needed\n",
        "%pip install -q kagglehub\n",
        "\n",
        "import kagglehub\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"\\n[INFO] Downloading FER2013 (Emotion Recognition Dataset)...\")\n",
        "print(\"   Size: ~50MB, Time: ~5-10 minutes\\n\")\n",
        "fer2013_path = kagglehub.dataset_download(\"msambare/fer2013\")\n",
        "print(f\"[OK] FER2013 downloaded to: {fer2013_path}\")\n",
        "\n",
        "print(\"\\n[INFO] Downloading UTKFace (Age & Gender Dataset)...\")\n",
        "print(\"   Size: ~300MB, Time: ~10-15 minutes\\n\")\n",
        "utkface_path = kagglehub.dataset_download(\"jangedoo/utkface-new\")\n",
        "print(f\"[OK] UTKFace downloaded to: {utkface_path}\")\n",
        "\n",
        "# Save paths for later use\n",
        "paths_file = '/content/dataset_paths.txt'\n",
        "with open(paths_file, 'w') as f:\n",
        "    f.write(f\"FER2013: {fer2013_path}\\n\")\n",
        "    f.write(f\"UTKFace: {utkface_path}\\n\")\n",
        "\n",
        "print(f\"\\n[OK] All datasets downloaded successfully!\")\n",
        "print(f\"[INFO] Paths saved to: {paths_file}\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 5: INSTALL DEPENDENCIES\n",
        "# ============================================================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"INSTALLING DEPENDENCIES\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\n[INFO] Installing required packages...\")\n",
        "%pip install -q albumentations tensorboard onnx onnxscript onnxruntime\n",
        "\n",
        "print(\"\\n[OK] All dependencies installed!\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 6: START TRAINING\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"STARTING TRAINING\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Read dataset paths\n",
        "with open('/content/dataset_paths.txt') as f:\n",
        "    lines = f.read().strip().split('\\n')\n",
        "    fer2013_path = lines[0].split(': ')[1]\n",
        "    utkface_path = lines[1].split(': ')[1]\n",
        "\n",
        "# Training configuration\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE = 0.001\n",
        "SAVE_DIR = \"/content/checkpoints\"\n",
        "\n",
        "print(f\"\\n[CONFIG] Training Configuration:\")\n",
        "print(f\"   Epochs: {EPOCHS}\")\n",
        "print(f\"   Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"   Learning Rate: {LEARNING_RATE}\")\n",
        "print(f\"   Dataset (Emotion): {fer2013_path}\")\n",
        "print(f\"   Dataset (Age/Gender): {utkface_path}\")\n",
        "print(f\"   Save Directory: {SAVE_DIR}\")\n",
        "print(f\"   Device: GPU T4\")\n",
        "\n",
        "# Pull latest code (in case of updates)\n",
        "print(f\"\\n[INFO] Pulling latest code...\")\n",
        "%cd /content/repo\n",
        "!git pull\n",
        "print(\"[OK] Code updated!\")\n",
        "\n",
        "# Navigate to training directory\n",
        "%cd /content/repo/training_experiments\n",
        "\n",
        "# Verify training script exists\n",
        "if not os.path.exists('train_colab_simple.py'):\n",
        "    print(\"\\n[WARN] Training script not found!\")\n",
        "    print(\"   Trying to re-clone repository...\")\n",
        "    %cd /content\n",
        "    !rm -rf /content/repo\n",
        "    !git clone https://github.com/khoiabc2020/age-gender-emotion-detection.git /content/repo\n",
        "    %cd /content/repo/training_experiments\n",
        "\n",
        "print(f\"\\n[START] Starting training... (This will take ~45-60 minutes)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Run training with simplified script\n",
        "!python train_colab_simple.py \\\n",
        "    --data_dir {fer2013_path} \\\n",
        "    --epochs {EPOCHS} \\\n",
        "    --batch_size {BATCH_SIZE} \\\n",
        "    --lr {LEARNING_RATE} \\\n",
        "    --save_dir {SAVE_DIR}\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"[OK] TRAINING COMPLETED!\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 8: SAVE RESULTS TO GOOGLE DRIVE\n",
        "# ============================================================\n",
        "\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"SAVING TO GOOGLE DRIVE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Source and destination\n",
        "checkpoint_dir = Path(\"/content/checkpoints\")\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "drive_dir = Path(f\"/content/drive/MyDrive/SmartRetailAI_Models/training_{timestamp}\")\n",
        "drive_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "if checkpoint_dir.exists():\n",
        "    print(f\"\\nüì¶ Copying files to Google Drive...\")\n",
        "    \n",
        "    file_count = 0\n",
        "    total_size = 0\n",
        "    \n",
        "    for file in checkpoint_dir.glob(\"*\"):\n",
        "        if file.is_file():\n",
        "            shutil.copy(file, drive_dir / file.name)\n",
        "            size_mb = file.stat().st_size / 1024 / 1024\n",
        "            print(f\"   ‚úÖ {file.name} ({size_mb:.1f} MB)\")\n",
        "            file_count += 1\n",
        "            total_size += size_mb\n",
        "    \n",
        "    print(f\"\\n‚úÖ Successfully saved {file_count} files ({total_size:.1f} MB total)\")\n",
        "    print(f\"üìÅ Location: {drive_dir}\")\n",
        "else:\n",
        "    print(\"\\n‚ùå Checkpoint directory not found!\")\n",
        "    print(\"   Training may have failed. Check errors above.\")\n",
        "\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 9: TRAINING SUMMARY\n",
        "# ============================================================\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"TRAINING SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Try to load results\n",
        "results_file = Path(\"/content/checkpoints/training_results.json\")\n",
        "\n",
        "if results_file.exists():\n",
        "    with open(results_file) as f:\n",
        "        results = json.load(f)\n",
        "    \n",
        "    print(f\"\\nüìä Training Results:\")\n",
        "    print(f\"   Gender Accuracy: {results.get('gender_accuracy', 'N/A')}%\")\n",
        "    print(f\"   Emotion Accuracy: {results.get('emotion_accuracy', 'N/A')}%\")\n",
        "    print(f\"   Age MAE: {results.get('age_mae', 'N/A')} years\")\n",
        "    print(f\"   Training Time: {results.get('training_time', 'N/A')} minutes\")\n",
        "    print(f\"   Best Epoch: {results.get('best_epoch', 'N/A')}\")\n",
        "else:\n",
        "    print(f\"\\nüìä Training completed!\")\n",
        "    print(f\"   Check your files in Google Drive:\")\n",
        "    print(f\"   MyDrive ‚Üí SmartRetailAI_Models\")\n",
        "\n",
        "print(f\"\\nüì• Next Steps:\")\n",
        "print(f\"   1. Download model.onnx from Google Drive\")\n",
        "print(f\"   2. Copy to your edge app: ai_edge_app/models/\")\n",
        "print(f\"   3. Test the edge app with new model\")\n",
        "print(f\"   4. Update documentation with results\")\n",
        "\n",
        "print(\"\\n‚úÖ ALL DONE!\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXS0Jy5PJIzf"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# Option 1: Copy t·ª´ Google Drive (n·∫øu ƒë√£ upload)\n",
        "DRIVE_DATA_DIR = '/content/drive/MyDrive/age_gender_emotion_data'\n",
        "LOCAL_DATA_DIR = Path('/content/project/training_experiments/data/processed')\n",
        "\n",
        "if os.path.exists(DRIVE_DATA_DIR):\n",
        "    print(f\"üìÅ Copy d·ªØ li·ªáu t·ª´ Drive...\")\n",
        "    shutil.copytree(DRIVE_DATA_DIR, LOCAL_DATA_DIR, dirs_exist_ok=True)\n",
        "    print(f\"‚úÖ ƒê√£ copy d·ªØ li·ªáu\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  Ch∆∞a c√≥ d·ªØ li·ªáu tr√™n Drive\")\n",
        "    print(f\"   Upload d·ªØ li·ªáu v√†o: {DRIVE_DATA_DIR}\")\n",
        "    print(f\"   Ho·∫∑c s·ª≠ d·ª•ng cell ti·∫øp theo ƒë·ªÉ download t·ª´ Kaggle\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGsaxOu6JIzf"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "data_dir = Path('/content/project/training_experiments/data/processed')\n",
        "train_dir = data_dir / 'train'\n",
        "val_dir = data_dir / 'val'\n",
        "test_dir = data_dir / 'test'\n",
        "\n",
        "print(\"üìä Ki·ªÉm tra d·ªØ li·ªáu:\")\n",
        "print(f\"   Train: {train_dir.exists()}\")\n",
        "print(f\"   Val: {val_dir.exists()}\")\n",
        "print(f\"   Test: {test_dir.exists()}\")\n",
        "\n",
        "if train_dir.exists():\n",
        "    train_images = list(train_dir.glob('**/*.jpg')) + list(train_dir.glob('**/*.png'))\n",
        "    val_images = list(val_dir.glob('**/*.jpg')) + list(val_dir.glob('**/*.png')) if val_dir.exists() else []\n",
        "    test_images = list(test_dir.glob('**/*.jpg')) + list(test_dir.glob('**/*.png')) if test_dir.exists() else []\n",
        "\n",
        "    print(f\"\\nüì∏ S·ªë l∆∞·ª£ng ·∫£nh:\")\n",
        "    print(f\"   Train: {len(train_images)}\")\n",
        "    print(f\"   Val: {len(val_images)}\")\n",
        "    print(f\"   Test: {len(test_images)}\")\n",
        "\n",
        "    if len(train_images) == 0:\n",
        "        print(\"\\n‚ö†Ô∏è  Ch∆∞a c√≥ ·∫£nh trong th∆∞ m·ª•c train!\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  Ch∆∞a c√≥ d·ªØ li·ªáu processed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ah0y0yNnJIzg"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Th√™m project v√†o Python path\n",
        "project_dir = Path('/content/project/training_experiments')\n",
        "sys.path.insert(0, str(project_dir))\n",
        "os.chdir(project_dir)\n",
        "\n",
        "# C·∫•u h√¨nh training\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 1e-3\n",
        "USE_QAT = True\n",
        "USE_DISTILLATION = True\n",
        "\n",
        "print(\"üöÄ B·∫Øt ƒë·∫ßu training t·ª± ƒë·ªông...\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"‚öôÔ∏è  C·∫•u h√¨nh:\")\n",
        "print(f\"   Epochs: {EPOCHS}\")\n",
        "print(f\"   Batch size: {BATCH_SIZE}\")\n",
        "print(f\"   Learning rate: {LEARNING_RATE}\")\n",
        "print(f\"   QAT: {USE_QAT}\")\n",
        "print(f\"   Distillation: {USE_DISTILLATION}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Build command\n",
        "cmd = f\"python train_week2_lightweight.py --data_dir data/processed --epochs {EPOCHS} --batch_size {BATCH_SIZE} --lr {LEARNING_RATE} --save_dir checkpoints/week2_colab --num_workers 2\"\n",
        "\n",
        "if USE_QAT:\n",
        "    cmd += \" --use_qat\"\n",
        "if USE_DISTILLATION:\n",
        "    cmd += \" --use_distillation\"\n",
        "\n",
        "# Ch·∫°y training\n",
        "os.system(cmd)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"‚úÖ Training ho√†n t·∫•t!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4bKX9wzJIzg"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "# T·∫°o th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£ v·ªõi timestamp\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "results_dir = Path(DRIVE_RESULTS_DIR) / f'training_{timestamp}'\n",
        "results_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Copy checkpoints\n",
        "checkpoint_dir = Path('/content/project/training_experiments/checkpoints/week2_colab')\n",
        "if checkpoint_dir.exists():\n",
        "    print(f\"üì¶ Copy checkpoints...\")\n",
        "    shutil.copytree(checkpoint_dir, results_dir / 'checkpoints', dirs_exist_ok=True)\n",
        "    print(f\"‚úÖ ƒê√£ copy checkpoints\")\n",
        "\n",
        "# Copy logs\n",
        "logs_dir = checkpoint_dir / 'logs'\n",
        "if logs_dir.exists():\n",
        "    print(f\"üìä Copy logs...\")\n",
        "    shutil.copytree(logs_dir, results_dir / 'logs', dirs_exist_ok=True)\n",
        "    print(f\"‚úÖ ƒê√£ copy logs\")\n",
        "\n",
        "# Copy ONNX model\n",
        "onnx_file = checkpoint_dir / 'mobileone_multitask.onnx'\n",
        "if onnx_file.exists():\n",
        "    print(f\"üìÑ Copy ONNX model...\")\n",
        "    shutil.copy2(onnx_file, results_dir / 'mobileone_multitask.onnx')\n",
        "    print(f\"‚úÖ ƒê√£ copy ONNX model\")\n",
        "\n",
        "print(f\"\\n‚úÖ T·∫•t c·∫£ k·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i:\")\n",
        "print(f\"   {results_dir}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
