{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ Training T·ª± ƒê·ªông tr√™n Google Colab\n",
        "\n",
        "Notebook n√†y s·∫Ω t·ª± ƒë·ªông:\n",
        "1. ‚úÖ C√†i ƒë·∫∑t dependencies\n",
        "2. ‚úÖ Ki·ªÉm tra GPU\n",
        "3. ‚úÖ Mount Google Drive\n",
        "4. ‚úÖ Download code t·ª´ Google Drive\n",
        "5. ‚úÖ Download/Setup d·ªØ li·ªáu\n",
        "6. ‚úÖ Ch·∫°y training t·ª± ƒë·ªông\n",
        "7. ‚úÖ L∆∞u k·∫øt qu·∫£ v·ªÅ Google Drive\n",
        "\n",
        "**L∆∞u √Ω**: Ch·ªçn GPU runtime tr∆∞·ªõc khi ch·∫°y!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# C√†i ƒë·∫∑t dependencies\n",
        "%pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "%pip install -q albumentations tqdm tensorboard onnx onnxruntime\n",
        "%pip install -q pandas numpy Pillow opencv-python\n",
        "%pip install -q kagglehub\n",
        "\n",
        "print(\"‚úÖ ƒê√£ c√†i ƒë·∫∑t xong c√°c th∆∞ vi·ªán!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.cuda as cuda\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {cuda.is_available()}\")\n",
        "if cuda.is_available():\n",
        "    print(f\"CUDA version: {cuda.version()}\")\n",
        "    print(f\"GPU device: {cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU memory: {cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Kh√¥ng c√≥ GPU! Vui l√≤ng ch·ªçn GPU runtime:\")\n",
        "    print(\"   Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# T·∫°o th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£\n",
        "DRIVE_RESULTS_DIR = '/content/drive/MyDrive/age_gender_emotion_training'\n",
        "os.makedirs(DRIVE_RESULTS_DIR, exist_ok=True)\n",
        "print(f\"‚úÖ ƒê√£ mount Google Drive\")\n",
        "print(f\"üìÅ K·∫øt qu·∫£ s·∫Ω l∆∞u t·∫°i: {DRIVE_RESULTS_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# ============================================================\n",
        "# OPTION 1: Clone t·ª´ GitHub (KHUY·∫æN NGH·ªä - T·ª± ƒë·ªông c·∫≠p nh·∫≠t)\n",
        "# ============================================================\n",
        "USE_GITHUB = True  # ƒê·ªïi th√†nh False n·∫øu mu·ªën d√πng zip\n",
        "GITHUB_REPO_URL = \"https://github.com/khoiabc2020/age-gender-emotion-detection.git\"  # Repository URL\n",
        "\n",
        "if USE_GITHUB:\n",
        "    project_dir = Path('/content/project/training_experiments')\n",
        "    \n",
        "    if project_dir.exists():\n",
        "        # Pull code m·ªõi nh·∫•t\n",
        "        print(\"üîÑ ƒêang pull code m·ªõi nh·∫•t t·ª´ GitHub...\")\n",
        "        os.system(f\"cd {project_dir} && git pull\")\n",
        "        print(\"‚úÖ ƒê√£ c·∫≠p nh·∫≠t code t·ª´ GitHub\")\n",
        "    else:\n",
        "        # Clone repo\n",
        "        print(f\"üì• ƒêang clone t·ª´ GitHub: {GITHUB_REPO_URL}\")\n",
        "        os.system(f\"cd /content/project && git clone {GITHUB_REPO_URL} training_experiments\")\n",
        "        \n",
        "        if project_dir.exists():\n",
        "            print(f\"‚úÖ ƒê√£ clone code t·ª´ GitHub\")\n",
        "        else:\n",
        "            print(\"‚ùå L·ªói khi clone. Ki·ªÉm tra l·∫°i URL repo.\")\n",
        "            USE_GITHUB = False\n",
        "\n",
        "# ============================================================\n",
        "# OPTION 2: Download t·ª´ Google Drive (file zip)\n",
        "# ============================================================\n",
        "if not USE_GITHUB:\n",
        "    # ƒê∆∞·ªùng d·∫´n file zip tr√™n Drive\n",
        "    import glob\n",
        "    zip_files = glob.glob('/content/drive/MyDrive/Colab_Training/training_experiments_*.zip')\n",
        "    \n",
        "    if zip_files:\n",
        "        # L·∫•y file m·ªõi nh·∫•t\n",
        "        latest_zip = max(zip_files, key=os.path.getctime)\n",
        "        print(f\"üì¶ T√¨m th·∫•y file: {os.path.basename(latest_zip)}\")\n",
        "        \n",
        "        # Gi·∫£i n√©n\n",
        "        print(\"üìÇ ƒêang gi·∫£i n√©n...\")\n",
        "        with zipfile.ZipFile(latest_zip, 'r') as zip_ref:\n",
        "            zip_ref.extractall('/content/project')\n",
        "        print(\"‚úÖ ƒê√£ gi·∫£i n√©n code\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y file zip tr√™n Drive\")\n",
        "        print(\"   H√£y upload file zip v√†o: /content/drive/MyDrive/Colab_Training/\")\n",
        "\n",
        "# Ki·ªÉm tra c·∫•u tr√∫c\n",
        "project_dir = Path('/content/project/training_experiments')\n",
        "if project_dir.exists():\n",
        "    print(f\"\\n‚úÖ Code ƒë√£ s·∫µn s√†ng t·∫°i: {project_dir}\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  C·∫ßn ki·ªÉm tra l·∫°i c·∫•u tr√∫c th∆∞ m·ª•c\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# Option 1: Copy t·ª´ Google Drive (n·∫øu ƒë√£ upload)\n",
        "DRIVE_DATA_DIR = '/content/drive/MyDrive/age_gender_emotion_data'\n",
        "LOCAL_DATA_DIR = Path('/content/project/training_experiments/data/processed')\n",
        "\n",
        "if os.path.exists(DRIVE_DATA_DIR):\n",
        "    print(f\"üìÅ Copy d·ªØ li·ªáu t·ª´ Drive...\")\n",
        "    shutil.copytree(DRIVE_DATA_DIR, LOCAL_DATA_DIR, dirs_exist_ok=True)\n",
        "    print(f\"‚úÖ ƒê√£ copy d·ªØ li·ªáu\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  Ch∆∞a c√≥ d·ªØ li·ªáu tr√™n Drive\")\n",
        "    print(f\"   Upload d·ªØ li·ªáu v√†o: {DRIVE_DATA_DIR}\")\n",
        "    print(f\"   Ho·∫∑c s·ª≠ d·ª•ng cell ti·∫øp theo ƒë·ªÉ download t·ª´ Kaggle\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "data_dir = Path('/content/project/training_experiments/data/processed')\n",
        "train_dir = data_dir / 'train'\n",
        "val_dir = data_dir / 'val'\n",
        "test_dir = data_dir / 'test'\n",
        "\n",
        "print(\"üìä Ki·ªÉm tra d·ªØ li·ªáu:\")\n",
        "print(f\"   Train: {train_dir.exists()}\")\n",
        "print(f\"   Val: {val_dir.exists()}\")\n",
        "print(f\"   Test: {test_dir.exists()}\")\n",
        "\n",
        "if train_dir.exists():\n",
        "    train_images = list(train_dir.glob('**/*.jpg')) + list(train_dir.glob('**/*.png'))\n",
        "    val_images = list(val_dir.glob('**/*.jpg')) + list(val_dir.glob('**/*.png')) if val_dir.exists() else []\n",
        "    test_images = list(test_dir.glob('**/*.jpg')) + list(test_dir.glob('**/*.png')) if test_dir.exists() else []\n",
        "    \n",
        "    print(f\"\\nüì∏ S·ªë l∆∞·ª£ng ·∫£nh:\")\n",
        "    print(f\"   Train: {len(train_images)}\")\n",
        "    print(f\"   Val: {len(val_images)}\")\n",
        "    print(f\"   Test: {len(test_images)}\")\n",
        "    \n",
        "    if len(train_images) == 0:\n",
        "        print(\"\\n‚ö†Ô∏è  Ch∆∞a c√≥ ·∫£nh trong th∆∞ m·ª•c train!\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  Ch∆∞a c√≥ d·ªØ li·ªáu processed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Th√™m project v√†o Python path\n",
        "project_dir = Path('/content/project/training_experiments')\n",
        "sys.path.insert(0, str(project_dir))\n",
        "os.chdir(project_dir)\n",
        "\n",
        "# C·∫•u h√¨nh training\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 1e-3\n",
        "USE_QAT = True\n",
        "USE_DISTILLATION = True\n",
        "\n",
        "print(\"üöÄ B·∫Øt ƒë·∫ßu training t·ª± ƒë·ªông...\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"‚öôÔ∏è  C·∫•u h√¨nh:\")\n",
        "print(f\"   Epochs: {EPOCHS}\")\n",
        "print(f\"   Batch size: {BATCH_SIZE}\")\n",
        "print(f\"   Learning rate: {LEARNING_RATE}\")\n",
        "print(f\"   QAT: {USE_QAT}\")\n",
        "print(f\"   Distillation: {USE_DISTILLATION}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Build command\n",
        "cmd = f\"python train_week2_lightweight.py --data_dir data/processed --epochs {EPOCHS} --batch_size {BATCH_SIZE} --lr {LEARNING_RATE} --save_dir checkpoints/week2_colab --num_workers 2\"\n",
        "\n",
        "if USE_QAT:\n",
        "    cmd += \" --use_qat\"\n",
        "if USE_DISTILLATION:\n",
        "    cmd += \" --use_distillation\"\n",
        "\n",
        "# Ch·∫°y training\n",
        "os.system(cmd)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"‚úÖ Training ho√†n t·∫•t!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "# T·∫°o th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£ v·ªõi timestamp\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "results_dir = Path(DRIVE_RESULTS_DIR) / f'training_{timestamp}'\n",
        "results_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Copy checkpoints\n",
        "checkpoint_dir = Path('/content/project/training_experiments/checkpoints/week2_colab')\n",
        "if checkpoint_dir.exists():\n",
        "    print(f\"üì¶ Copy checkpoints...\")\n",
        "    shutil.copytree(checkpoint_dir, results_dir / 'checkpoints', dirs_exist_ok=True)\n",
        "    print(f\"‚úÖ ƒê√£ copy checkpoints\")\n",
        "\n",
        "# Copy logs\n",
        "logs_dir = checkpoint_dir / 'logs'\n",
        "if logs_dir.exists():\n",
        "    print(f\"üìä Copy logs...\")\n",
        "    shutil.copytree(logs_dir, results_dir / 'logs', dirs_exist_ok=True)\n",
        "    print(f\"‚úÖ ƒê√£ copy logs\")\n",
        "\n",
        "# Copy ONNX model\n",
        "onnx_file = checkpoint_dir / 'mobileone_multitask.onnx'\n",
        "if onnx_file.exists():\n",
        "    print(f\"üìÑ Copy ONNX model...\")\n",
        "    shutil.copy2(onnx_file, results_dir / 'mobileone_multitask.onnx')\n",
        "    print(f\"‚úÖ ƒê√£ copy ONNX model\")\n",
        "\n",
        "print(f\"\\n‚úÖ T·∫•t c·∫£ k·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i:\")\n",
        "print(f\"   {results_dir}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
