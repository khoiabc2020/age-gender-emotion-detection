# Optimized Kaggle Training Guide - 9 Cells Complete

## Target: 75-80% Accuracy (Realistic for FER2013)

**Status:** All cells fixed and optimized  
**Time:** 6-8 hours (P100 GPU)  
**Datasets:** Currently using FER2013 only (28K images)

---

## Current Setup (1 Dataset)

**Dataset:** FER2013 only  
**Expected:** 75-80% accuracy  
**Why not 4 datasets yet?** Need to add RAF-DB + AffectNet in Cell 3 and Cell 5

---

## CELL 1: Check GPU

```python
import torch
import torch.cuda as cuda

print("PyTorch version:", torch.__version__)
print("CUDA available:", cuda.is_available())

if cuda.is_available():
    print("CUDA version:", torch.version.cuda)
    print("GPU device:", cuda.get_device_name(0))
    print(f"GPU memory: {cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
else:
    print("WARNING: No GPU available!")
```

---

## CELL 2: Clone Repository

```python
import os
from pathlib import Path

repo_url = "https://github.com/khoiabc2020/age-gender-emotion-detection.git"
repo_dir = Path("/kaggle/working/repo")

if repo_dir.exists():
    print("[INFO] Repository exists, pulling latest changes...")
    !cd /kaggle/working/repo && git pull
else:
    print("[INFO] Cloning repository...")
    !git clone {repo_url} /kaggle/working/repo

%cd /kaggle/working/repo/training_experiments
print("\n[OK] Repository ready!")
print(f"Working directory: {os.getcwd()}")
```

---

## CELL 3: Check Datasets (1 dataset currently)

‚ö†Ô∏è **Current:** Only FER2013  
‚ú® **To use 4 datasets:** See "4 Datasets Version" section below

```python
import json
from pathlib import Path

dataset_paths = {}

# FER2013 - Main emotion dataset
fer_path = '/kaggle/input/fer2013'
if Path(fer_path).exists():
    dataset_paths['fer2013'] = fer_path
    print(f"[OK] FER2013: {fer_path}")
else:
    print(f"[ERROR] FER2013 not found!")

# Optional: UTKFace for age/gender
utk_path = '/kaggle/input/utkface-new'
if Path(utk_path).exists():
    dataset_paths['utkface'] = utk_path
    print(f"[OK] UTKFace: {utk_path}")

# Save paths
paths_file = '/kaggle/working/dataset_paths.json'
with open(paths_file, 'w') as f:
    json.dump(dataset_paths, f, indent=2)

print(f"\n[INFO] Total datasets: {len(dataset_paths)}")
print(f"[INFO] Paths saved to: {paths_file}")
```

---

## CELL 4: Install Dependencies

```python
print("Installing dependencies...")
%pip install -q timm albumentations tensorboard onnx onnxscript onnxruntime torchmetrics
print("\n[OK] All dependencies installed!")
```

---

## CELL 5: Optimized Training (FER2013 only - 75-80% target)

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import timm
import json
from pathlib import Path
from tqdm import tqdm
import time
import numpy as np

print("=" * 60)
print("OPTIMIZED TRAINING FOR KAGGLE P100")
print("Target: 75-80% (FER2013 only)")
print("=" * 60)

# Configuration
EPOCHS = 120
BATCH_SIZE = 48
LEARNING_RATE = 0.0002
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
EARLY_STOPPING_PATIENCE = 30
WARMUP_EPOCHS = 5

print(f"\n[CONFIG] Settings:")
print(f"  Model: EfficientNet-B0")
print(f"  Batch Size: {BATCH_SIZE}")
print(f"  Learning Rate: {LEARNING_RATE}")
print(f"  Max Epochs: {EPOCHS}")
print(f"  Patience: {EARLY_STOPPING_PATIENCE}")

# Load datasets
with open('/kaggle/working/dataset_paths.json') as f:
    dataset_paths = json.load(f)

fer2013_path = Path(dataset_paths['fer2013'])

if (fer2013_path / 'train').exists():
    train_path = fer2013_path / 'train'
    test_path = fer2013_path / 'test'
else:
    subdirs = list(fer2013_path.glob('**/train'))
    if subdirs:
        train_path = subdirs[0]
        test_path = subdirs[0].parent / 'test'

print(f"\n[INFO] Dataset: {fer2013_path}")

# Strong augmentation
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.Grayscale(num_output_channels=3),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(15),
    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),
    transforms.RandomPerspective(distortion_scale=0.2, p=0.3),
    transforms.ToTensor(),
    transforms.ColorJitter(brightness=0.25, contrast=0.25),
    transforms.RandomErasing(p=0.3, scale=(0.02, 0.25)),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

test_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.Grayscale(num_output_channels=3),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

train_dataset = datasets.ImageFolder(train_path, transform=train_transform)
test_dataset = datasets.ImageFolder(test_path, transform=test_transform)

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)

num_classes = len(train_dataset.classes)
class_names = train_dataset.classes

print(f"[OK] Train: {len(train_dataset)}, Test: {len(test_dataset)}, Classes: {num_classes}")

# Model with heavy regularization
print("\n[INFO] Creating EfficientNet-B0 (dropout=0.6)...")
model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=num_classes, drop_rate=0.6)
model = model.to(DEVICE)
print(f"[OK] Model ready")

# Focal Loss
class FocalLoss(nn.Module):
    def __init__(self, alpha=1, gamma=2.5, label_smoothing=0.2):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.label_smoothing = label_smoothing
        
    def forward(self, inputs, targets):
        ce_loss = nn.CrossEntropyLoss(label_smoothing=self.label_smoothing)(inputs, targets)
        pt = torch.exp(-ce_loss)
        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss
        return focal_loss

criterion = FocalLoss(alpha=1, gamma=2.5, label_smoothing=0.2)
print("[OK] Focal Loss (gamma=2.5, smoothing=0.2)")

# Optimizer
optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.03, betas=(0.9, 0.999))

# LR Scheduler with warmup
def get_lr_scheduler(optimizer, warmup_epochs, total_epochs):
    def lr_lambda(epoch):
        if epoch < warmup_epochs:
            return (epoch + 1) / warmup_epochs
        else:
            progress = (epoch - warmup_epochs) / (total_epochs - warmup_epochs)
            return 0.5 * (1 + np.cos(np.pi * progress))
    return optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)

scheduler = get_lr_scheduler(optimizer, WARMUP_EPOCHS, EPOCHS)
print("[OK] AdamW + Cosine with Warmup")

# Mixup
def mixup_data(x, y, alpha=0.3):
    if alpha > 0:
        lam = np.random.beta(alpha, alpha)
    else:
        lam = 1
    batch_size = x.size()[0]
    index = torch.randperm(batch_size).to(x.device)
    mixed_x = lam * x + (1 - lam) * x[index, :]
    y_a, y_b = y, y[index]
    return mixed_x, y_a, y_b, lam

def mixup_criterion(criterion, pred, y_a, y_b, lam):
    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)

print("[OK] Mixup (alpha=0.3)")

# Training loop
print("\n" + "=" * 60)
print("STARTING TRAINING")
print("=" * 60)

best_accuracy = 0
best_epoch = 0
patience_counter = 0
start_time = time.time()

history = {'train_loss': [], 'train_acc': [], 'test_acc': [], 'lr': []}

for epoch in range(EPOCHS):
    model.train()
    train_loss = 0
    train_correct = 0
    train_total = 0
    
    current_lr = optimizer.param_groups[0]['lr']
    
    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{EPOCHS}')
    for batch_idx, (images, labels) in enumerate(pbar):
        images, labels = images.to(DEVICE), labels.to(DEVICE)
        
        # Mixup 60% of batches
        if np.random.rand() > 0.4:
            images, labels_a, labels_b, lam = mixup_data(images, labels, alpha=0.3)
            optimizer.zero_grad()
            outputs = model(images)
            loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)
        else:
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
        
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()
        
        train_loss += loss.item()
        _, predicted = outputs.max(1)
        train_total += labels.size(0)
        train_correct += predicted.eq(labels).sum().item()
        
        pbar.set_postfix({'loss': f'{train_loss/(batch_idx+1):.4f}', 'acc': f'{100.*train_correct/train_total:.2f}%'})
    
    train_acc = 100. * train_correct / train_total
    avg_train_loss = train_loss / len(train_loader)
    
    # Validation
    model.eval()
    test_correct = 0
    test_total = 0
    
    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(DEVICE), labels.to(DEVICE)
            outputs = model(images)
            _, predicted = outputs.max(1)
            test_total += labels.size(0)
            test_correct += predicted.eq(labels).sum().item()
    
    test_acc = 100. * test_correct / test_total
    scheduler.step()
    
    history['train_loss'].append(float(avg_train_loss))
    history['train_acc'].append(float(train_acc))
    history['test_acc'].append(float(test_acc))
    history['lr'].append(float(current_lr))
    
    elapsed = time.time() - start_time
    print(f"\nEpoch {epoch+1}: Loss={avg_train_loss:.4f}, Train={train_acc:.2f}%, Val={test_acc:.2f}%, LR={current_lr:.7f}, Time={elapsed/60:.1f}m")
    
    # Save best
    if test_acc > best_accuracy:
        best_accuracy = test_acc
        best_epoch = epoch + 1
        patience_counter = 0
        
        save_dir = Path('/kaggle/working/checkpoints_production')
        save_dir.mkdir(parents=True, exist_ok=True)
        
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'best_accuracy': best_accuracy,
            'class_names': class_names,
            'num_classes': num_classes,
            'config': {
                'batch_size': BATCH_SIZE,
                'learning_rate': LEARNING_RATE,
                'model': 'efficientnet_b0',
                'dropout': 0.6
            }
        }
        
        torch.save(checkpoint, save_dir / 'best_model_optimized.pth')
        print(f"[NEW BEST] {best_accuracy:.2f}%")
    else:
        patience_counter += 1
        print(f"No improvement: {patience_counter}/{EARLY_STOPPING_PATIENCE}")
    
    if patience_counter >= EARLY_STOPPING_PATIENCE:
        print(f"\n[STOP] Early stopping")
        break

# Save results
total_time = time.time() - start_time

results = {
    'best_accuracy': float(best_accuracy),
    'best_epoch': int(best_epoch),
    'total_epochs': epoch + 1,
    'training_time_hours': float(total_time/3600),
    'num_classes': num_classes,
    'class_names': class_names,
    'history': history,
    'config': {
        'model': 'efficientnet_b0',
        'batch_size': BATCH_SIZE,
        'learning_rate': LEARNING_RATE,
        'dropout': 0.6
    }
}

save_dir = Path('/kaggle/working/checkpoints_production')
save_dir.mkdir(parents=True, exist_ok=True)

with open(save_dir / 'training_results.json', 'w') as f:
    json.dump(results, f, indent=2)

print("\n" + "=" * 60)
print("TRAINING COMPLETE")
print("=" * 60)
print(f"Best: {best_accuracy:.2f}%")
print(f"Time: {total_time/3600:.2f}h")
print("=" * 60)
```

---

## CELL 6-9: Results, Export, Download

(Same as provided earlier - check results, export ONNX, download files, summary)

---

## üî• 4 DATASETS VERSION (For 80-85%)

To use 4 datasets for higher accuracy, replace:

### Cell 3 (4 datasets):

```python
dataset_paths = {}

# 1. FER2013
fer_path = '/kaggle/input/fer2013'
if Path(fer_path).exists():
    dataset_paths['fer2013'] = fer_path
    print(f"[OK] FER2013")

# 2. UTKFace
utk_path = '/kaggle/input/utkface-new'
if Path(utk_path).exists():
    dataset_paths['utkface'] = utk_path
    print(f"[OK] UTKFace")

# 3. RAF-DB
rafdb_path = '/kaggle/input/raf-db-dataset'
if Path(rafdb_path).exists():
    dataset_paths['rafdb'] = rafdb_path
    print(f"[OK] RAF-DB")

# 4. AffectNet
affectnet_path = '/kaggle/input/affectnet-training-data'
if Path(affectnet_path).exists():
    dataset_paths['affectnet'] = affectnet_path
    print(f"[OK] AffectNet")

with open('/kaggle/working/dataset_paths.json', 'w') as f:
    json.dump(dataset_paths, f, indent=2)

print(f"\n[OK] {len(dataset_paths)} datasets ready")
```

### Cell 5 (Load 4 datasets):

Add before training loop:

```python
from torch.utils.data import ConcatDataset

# Load all available datasets
all_train_datasets = []
all_test_datasets = []

for name, path in dataset_paths.items():
    dataset_path = Path(path)
    if (dataset_path / 'train').exists():
        train_ds = datasets.ImageFolder(dataset_path / 'train', transform=train_transform)
        test_ds = datasets.ImageFolder(dataset_path / 'test', transform=test_transform)
        all_train_datasets.append(train_ds)
        all_test_datasets.append(test_ds)
        print(f"[OK] Loaded {name}: {len(train_ds)} train, {len(test_ds)} test")

# Combine datasets
train_dataset = ConcatDataset(all_train_datasets)
test_dataset = ConcatDataset(all_test_datasets)

print(f"\n[OK] Total train: {len(train_dataset)}, test: {len(test_dataset)}")
```

**Expected with 4 datasets: 80-85%**

---

## Summary

### Current (1 dataset - FER2013):
- Target: **75-80%**
- Time: 6-8h
- Good for: Emotion recognition only

### With 4 datasets:
- Target: **80-85%**
- Time: 10-12h
- Good for: Production deployment
- Need to: Add datasets in Kaggle first

---

**All cells optimized and ready!** üöÄ
