"""
Script t·ª± ƒë·ªông setup v√† ch·∫°y training tr√™n Colab
T·∫°o notebook t·ª± ƒë·ªông ch·∫°y v·ªõi t·∫•t c·∫£ c√°c b∆∞·ªõc
"""

import json
from pathlib import Path


def create_auto_run_notebook():
    """T·∫°o notebook t·ª± ƒë·ªông ch·∫°y"""
    
    # ƒê·ªçc notebook hi·ªán t·∫°i
    notebook_path = Path(__file__).parent.parent / 'notebooks' / 'train_on_colab.ipynb'
    
    # T·∫°o notebook m·ªõi v·ªõi auto-run
    notebook = {
        "cells": [],
        "metadata": {
            "accelerator": "GPU",
            "colab": {
                "gpuType": "T4",
                "provenance": []
            },
            "kernelspec": {
                "display_name": "Python 3",
                "name": "python3"
            },
            "language_info": {
                "name": "python"
            }
        },
        "nbformat": 4,
        "nbformat_minor": 0
    }
    
    # Cell 1: Markdown - H∆∞·ªõng d·∫´n
    notebook["cells"].append({
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "# üöÄ Training T·ª± ƒê·ªông tr√™n Google Colab\n",
            "\n",
            "Notebook n√†y s·∫Ω t·ª± ƒë·ªông:\n",
            "1. ‚úÖ C√†i ƒë·∫∑t dependencies\n",
            "2. ‚úÖ Ki·ªÉm tra GPU\n",
            "3. ‚úÖ Mount Google Drive\n",
            "4. ‚úÖ Download code t·ª´ Google Drive\n",
            "5. ‚úÖ Download/Setup d·ªØ li·ªáu\n",
            "6. ‚úÖ Ch·∫°y training t·ª± ƒë·ªông\n",
            "7. ‚úÖ L∆∞u k·∫øt qu·∫£ v·ªÅ Google Drive\n",
            "\n",
            "**L∆∞u √Ω**: Ch·ªçn GPU runtime tr∆∞·ªõc khi ch·∫°y!"
        ]
    })
    
    # Cell 2: C√†i ƒë·∫∑t dependencies
    notebook["cells"].append({
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# C√†i ƒë·∫∑t dependencies\n",
            "%pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
            "%pip install -q albumentations tqdm tensorboard onnx onnxruntime\n",
            "%pip install -q pandas numpy Pillow opencv-python\n",
            "%pip install -q kagglehub\n",
            "\n",
            "print(\"‚úÖ ƒê√£ c√†i ƒë·∫∑t xong c√°c th∆∞ vi·ªán!\")"
        ]
    })
    
    # Cell 3: Ki·ªÉm tra GPU
    notebook["cells"].append({
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "import torch\n",
            "import torch.cuda as cuda\n",
            "\n",
            "print(f\"PyTorch version: {torch.__version__}\")\n",
            "print(f\"CUDA available: {cuda.is_available()}\")\n",
            "if cuda.is_available():\n",
            "    print(f\"CUDA version: {cuda.version()}\")\n",
            "    print(f\"GPU device: {cuda.get_device_name(0)}\")\n",
            "    print(f\"GPU memory: {cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
            "else:\n",
            "    print(\"‚ö†Ô∏è  Kh√¥ng c√≥ GPU! Vui l√≤ng ch·ªçn GPU runtime:\")\n",
            "    print(\"   Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU\")"
        ]
    })
    
    # Cell 4: Mount Google Drive
    notebook["cells"].append({
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "from google.colab import drive\n",
            "import os\n",
            "\n",
            "# Mount Google Drive\n",
            "drive.mount('/content/drive')\n",
            "\n",
            "# T·∫°o th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£\n",
            "DRIVE_RESULTS_DIR = '/content/drive/MyDrive/age_gender_emotion_training'\n",
            "os.makedirs(DRIVE_RESULTS_DIR, exist_ok=True)\n",
            "print(f\"‚úÖ ƒê√£ mount Google Drive\")\n",
            "print(f\"üìÅ K·∫øt qu·∫£ s·∫Ω l∆∞u t·∫°i: {DRIVE_RESULTS_DIR}\")"
        ]
    })
    
    # Cell 5: Download code t·ª´ Google Drive
    notebook["cells"].append({
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "import zipfile\n",
            "import os\n",
            "from pathlib import Path\n",
            "\n",
            "# ƒê∆∞·ªùng d·∫´n file zip tr√™n Drive (thay ƒë·ªïi theo v·ªã tr√≠ file c·ªßa b·∫°n)\n",
            "DRIVE_CODE_ZIP = '/content/drive/MyDrive/Colab_Training/training_experiments_*.zip'\n",
            "\n",
            "# T√¨m file zip m·ªõi nh·∫•t\n",
            "import glob\n",
            "zip_files = glob.glob('/content/drive/MyDrive/Colab_Training/training_experiments_*.zip')\n",
            "\n",
            "if zip_files:\n",
            "    # L·∫•y file m·ªõi nh·∫•t\n",
            "    latest_zip = max(zip_files, key=os.path.getctime)\n",
            "    print(f\"üì¶ T√¨m th·∫•y file: {os.path.basename(latest_zip)}\")\n",
            "    \n",
            "    # Gi·∫£i n√©n\n",
            "    print(\"üìÇ ƒêang gi·∫£i n√©n...\")\n",
            "    with zipfile.ZipFile(latest_zip, 'r') as zip_ref:\n",
            "        zip_ref.extractall('/content/project')\n",
            "    print(\"‚úÖ ƒê√£ gi·∫£i n√©n code\")\n",
            "    \n",
            "    # Ki·ªÉm tra c·∫•u tr√∫c\n",
            "    project_dir = Path('/content/project/training_experiments')\n",
            "    if project_dir.exists():\n",
            "        print(f\"‚úÖ Code ƒë√£ s·∫µn s√†ng t·∫°i: {project_dir}\")\n",
            "    else:\n",
            "        print(\"‚ö†Ô∏è  C·∫ßn ki·ªÉm tra l·∫°i c·∫•u tr√∫c th∆∞ m·ª•c\")\n",
            "else:\n",
            "    print(\"‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y file zip tr√™n Drive\")\n",
            "    print(\"   H√£y upload file zip v√†o: /content/drive/MyDrive/Colab_Training/\")"
        ]
    })
    
    # Cell 6: Setup d·ªØ li·ªáu (t·ª´ Drive ho·∫∑c download)
    notebook["cells"].append({
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "import shutil\n",
            "from pathlib import Path\n",
            "\n",
            "# Option 1: Copy t·ª´ Google Drive (n·∫øu ƒë√£ upload)\n",
            "DRIVE_DATA_DIR = '/content/drive/MyDrive/age_gender_emotion_data'\n",
            "LOCAL_DATA_DIR = Path('/content/project/training_experiments/data/processed')\n",
            "\n",
            "if os.path.exists(DRIVE_DATA_DIR):\n",
            "    print(f\"üìÅ Copy d·ªØ li·ªáu t·ª´ Drive...\")\n",
            "    shutil.copytree(DRIVE_DATA_DIR, LOCAL_DATA_DIR, dirs_exist_ok=True)\n",
            "    print(f\"‚úÖ ƒê√£ copy d·ªØ li·ªáu\")\n",
            "else:\n",
            "    print(f\"‚ö†Ô∏è  Ch∆∞a c√≥ d·ªØ li·ªáu tr√™n Drive\")\n",
            "    print(f\"   Upload d·ªØ li·ªáu v√†o: {DRIVE_DATA_DIR}\")\n",
            "    print(f\"   Ho·∫∑c s·ª≠ d·ª•ng cell ti·∫øp theo ƒë·ªÉ download t·ª´ Kaggle\")"
        ]
    })
    
    # Cell 7: Ki·ªÉm tra d·ªØ li·ªáu
    notebook["cells"].append({
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "from pathlib import Path\n",
            "\n",
            "data_dir = Path('/content/project/training_experiments/data/processed')\n",
            "train_dir = data_dir / 'train'\n",
            "val_dir = data_dir / 'val'\n",
            "test_dir = data_dir / 'test'\n",
            "\n",
            "print(\"üìä Ki·ªÉm tra d·ªØ li·ªáu:\")\n",
            "print(f\"   Train: {train_dir.exists()}\")\n",
            "print(f\"   Val: {val_dir.exists()}\")\n",
            "print(f\"   Test: {test_dir.exists()}\")\n",
            "\n",
            "if train_dir.exists():\n",
            "    train_images = list(train_dir.glob('**/*.jpg')) + list(train_dir.glob('**/*.png'))\n",
            "    val_images = list(val_dir.glob('**/*.jpg')) + list(val_dir.glob('**/*.png')) if val_dir.exists() else []\n",
            "    test_images = list(test_dir.glob('**/*.jpg')) + list(test_dir.glob('**/*.png')) if test_dir.exists() else []\n",
            "    \n",
            "    print(f\"\\nüì∏ S·ªë l∆∞·ª£ng ·∫£nh:\")\n",
            "    print(f\"   Train: {len(train_images)}\")\n",
            "    print(f\"   Val: {len(val_images)}\")\n",
            "    print(f\"   Test: {len(test_images)}\")\n",
            "    \n",
            "    if len(train_images) == 0:\n",
            "        print(\"\\n‚ö†Ô∏è  Ch∆∞a c√≥ ·∫£nh trong th∆∞ m·ª•c train!\")\n",
            "else:\n",
            "    print(\"\\n‚ö†Ô∏è  Ch∆∞a c√≥ d·ªØ li·ªáu processed!\")"
        ]
    })
    
    # Cell 8: Ch·∫°y training t·ª± ƒë·ªông
    notebook["cells"].append({
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "import sys\n",
            "import os\n",
            "from pathlib import Path\n",
            "\n",
            "# Th√™m project v√†o Python path\n",
            "project_dir = Path('/content/project/training_experiments')\n",
            "sys.path.insert(0, str(project_dir))\n",
            "os.chdir(project_dir)\n",
            "\n",
            "# C·∫•u h√¨nh training\n",
            "EPOCHS = 50\n",
            "BATCH_SIZE = 32\n",
            "LEARNING_RATE = 1e-3\n",
            "USE_QAT = True\n",
            "USE_DISTILLATION = True\n",
            "\n",
            "print(\"üöÄ B·∫Øt ƒë·∫ßu training t·ª± ƒë·ªông...\")\n",
            "print(\"=\" * 60)\n",
            "print(f\"‚öôÔ∏è  C·∫•u h√¨nh:\")\n",
            "print(f\"   Epochs: {EPOCHS}\")\n",
            "print(f\"   Batch size: {BATCH_SIZE}\")\n",
            "print(f\"   Learning rate: {LEARNING_RATE}\")\n",
            "print(f\"   QAT: {USE_QAT}\")\n",
            "print(f\"   Distillation: {USE_DISTILLATION}\")\n",
            "print(\"=\" * 60)\n",
            "\n",
            "# Build command\n",
            "cmd = f\"python train_week2_lightweight.py --data_dir data/processed --epochs {EPOCHS} --batch_size {BATCH_SIZE} --lr {LEARNING_RATE} --save_dir checkpoints/week2_colab --num_workers 2\"\n",
            "\n",
            "if USE_QAT:\n",
            "    cmd += \" --use_qat\"\n",
            "if USE_DISTILLATION:\n",
            "    cmd += \" --use_distillation\"\n",
            "\n",
            "# Ch·∫°y training\n",
            "os.system(cmd)\n",
            "\n",
            "print(\"\\n\" + \"=\" * 60)\n",
            "print(\"‚úÖ Training ho√†n t·∫•t!\")"
        ]
    })
    
    # Cell 9: L∆∞u k·∫øt qu·∫£ v·ªÅ Drive
    notebook["cells"].append({
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "import shutil\n",
            "from datetime import datetime\n",
            "from pathlib import Path\n",
            "\n",
            "# T·∫°o th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£ v·ªõi timestamp\n",
            "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
            "results_dir = Path(DRIVE_RESULTS_DIR) / f'training_{timestamp}'\n",
            "results_dir.mkdir(parents=True, exist_ok=True)\n",
            "\n",
            "# Copy checkpoints\n",
            "checkpoint_dir = Path('/content/project/training_experiments/checkpoints/week2_colab')\n",
            "if checkpoint_dir.exists():\n",
            "    print(f\"üì¶ Copy checkpoints...\")\n",
            "    shutil.copytree(checkpoint_dir, results_dir / 'checkpoints', dirs_exist_ok=True)\n",
            "    print(f\"‚úÖ ƒê√£ copy checkpoints\")\n",
            "\n",
            "# Copy logs\n",
            "logs_dir = checkpoint_dir / 'logs'\n",
            "if logs_dir.exists():\n",
            "    print(f\"üìä Copy logs...\")\n",
            "    shutil.copytree(logs_dir, results_dir / 'logs', dirs_exist_ok=True)\n",
            "    print(f\"‚úÖ ƒê√£ copy logs\")\n",
            "\n",
            "# Copy ONNX model\n",
            "onnx_file = checkpoint_dir / 'mobileone_multitask.onnx'\n",
            "if onnx_file.exists():\n",
            "    print(f\"üìÑ Copy ONNX model...\")\n",
            "    shutil.copy2(onnx_file, results_dir / 'mobileone_multitask.onnx')\n",
            "    print(f\"‚úÖ ƒê√£ copy ONNX model\")\n",
            "\n",
            "print(f\"\\n‚úÖ T·∫•t c·∫£ k·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i:\")\n",
            "print(f\"   {results_dir}\")"
        ]
    })
    
    # L∆∞u notebook
    output_path = Path(__file__).parent.parent / 'notebooks' / 'train_on_colab_auto.ipynb'
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(notebook, f, indent=2, ensure_ascii=False)
    
    print(f"Da tao notebook tu dong: {output_path}")
    return output_path


if __name__ == "__main__":
    create_auto_run_notebook()

